{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c822f5f-54d4-4e2c-a619-a7589f5a5d8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bcd90a0-2b8f-4d93-bd9a-35b20873cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path containing python module for processing Stack Exchange posts.\n",
    "sys.path.insert(1, '../src')\n",
    "\n",
    "import se_post_processing as sepp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00d173f-42f4-4e0d-91ed-24ba8e870f48",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "---\n",
    "\n",
    "### 1. Introduction\n",
    "### 2. Data processing\n",
    "### 3. Modeling\n",
    "### 4. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d904b19c-8618-424d-ac33-08223003fd47",
   "metadata": {},
   "source": [
    "# 1. Introduction\n",
    "---\n",
    "\n",
    "In this notebook, we create our final model for predicting whether or not a question on the Data Science Stack Exchange will be answered within 7 days. We first process the text and engineer features from the contents of the post, then we train and evaluate a random forest model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705a607f-4e06-481b-8f62-3c7bc9348bd3",
   "metadata": {},
   "source": [
    "# 2. Data processing\n",
    "---\n",
    "\n",
    "We begin by preparing the Stack Exchange post data for modeling. We need to process the text in the bodies and titles of the questions to engineer features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6dd04f0-b804-4deb-b896-f07ab7fa4344",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>Title</th>\n",
       "      <th>Tags</th>\n",
       "      <th>...</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>ContentLicense</th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>LastEditDate</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>LastEditorDisplayName</th>\n",
       "      <th>FavoriteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-05-13T23:58:30.457</td>\n",
       "      <td>9</td>\n",
       "      <td>959.0</td>\n",
       "      <td>&lt;p&gt;I've always been interested in machine lear...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2014-05-14T00:36:31.077</td>\n",
       "      <td>How can I do simple machine learning without h...</td>\n",
       "      <td>&lt;machine-learning&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-05-14T14:40:25.950</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-05-14T00:11:06.457</td>\n",
       "      <td>4</td>\n",
       "      <td>503.0</td>\n",
       "      <td>&lt;p&gt;As a researcher and instructor, I'm looking...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>2014-05-16T13:45:00.237</td>\n",
       "      <td>What open-source books (or other materials) pr...</td>\n",
       "      <td>&lt;education&gt;&lt;open-source&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>2014-05-14T08:40:54.950</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2014-05-16T13:45:00.237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-05-14T00:36:31.077</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;Not sure if this fits the scope of this SE,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2014-05-14T00:36:31.077</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>5.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2014-05-14T00:53:43.273</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;p&gt;One book that's freely available is \"The El...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2014-05-14T00:53:43.273</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>7.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-05-14T01:25:59.677</td>\n",
       "      <td>26</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>&lt;p&gt;I am sure data science as will be discussed...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>2020-08-16T13:01:33.543</td>\n",
       "      <td>Is Data Science the Same as Data Mining?</td>\n",
       "      <td>&lt;data-mining&gt;&lt;definitions&gt;</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2014-06-17T16:17:20.473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  PostTypeId             CreationDate  Score  ViewCount  \\\n",
       "0   5           1  2014-05-13T23:58:30.457      9      959.0   \n",
       "1   7           1  2014-05-14T00:11:06.457      4      503.0   \n",
       "2   9           2  2014-05-14T00:36:31.077      5        NaN   \n",
       "3  10           2  2014-05-14T00:53:43.273     13        NaN   \n",
       "4  14           1  2014-05-14T01:25:59.677     26     1925.0   \n",
       "\n",
       "                                                Body  OwnerUserId  \\\n",
       "0  <p>I've always been interested in machine lear...          5.0   \n",
       "1  <p>As a researcher and instructor, I'm looking...         36.0   \n",
       "2  <p>Not sure if this fits the scope of this SE,...         51.0   \n",
       "3  <p>One book that's freely available is \"The El...         22.0   \n",
       "4  <p>I am sure data science as will be discussed...         66.0   \n",
       "\n",
       "          LastActivityDate                                              Title  \\\n",
       "0  2014-05-14T00:36:31.077  How can I do simple machine learning without h...   \n",
       "1  2014-05-16T13:45:00.237  What open-source books (or other materials) pr...   \n",
       "2  2014-05-14T00:36:31.077                                               None   \n",
       "3  2014-05-14T00:53:43.273                                               None   \n",
       "4  2020-08-16T13:01:33.543           Is Data Science the Same as Data Mining?   \n",
       "\n",
       "                         Tags  ...               ClosedDate  ContentLicense  \\\n",
       "0          <machine-learning>  ...  2014-05-14T14:40:25.950    CC BY-SA 3.0   \n",
       "1    <education><open-source>  ...  2014-05-14T08:40:54.950    CC BY-SA 3.0   \n",
       "2                        None  ...                     None    CC BY-SA 3.0   \n",
       "3                        None  ...                     None    CC BY-SA 3.0   \n",
       "4  <data-mining><definitions>  ...                     None    CC BY-SA 3.0   \n",
       "\n",
       "  AcceptedAnswerId LastEditorUserId             LastEditDate  ParentId  \\\n",
       "0              NaN              NaN                     None       NaN   \n",
       "1             10.0             97.0  2014-05-16T13:45:00.237       NaN   \n",
       "2              NaN              NaN                     None       5.0   \n",
       "3              NaN              NaN                     None       7.0   \n",
       "4             29.0            322.0  2014-06-17T16:17:20.473       NaN   \n",
       "\n",
       "  OwnerDisplayName  CommunityOwnedDate LastEditorDisplayName FavoriteCount  \n",
       "0             None                None                  None           NaN  \n",
       "1             None                None                  None           NaN  \n",
       "2             None                None                  None           NaN  \n",
       "3             None                None                  None           NaN  \n",
       "4             None                None                  None           NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read post data and insepct first five rows.\n",
    "posts = pd.read_xml('../data/ds/posts.xml')\n",
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abc4cfb3-c4c7-4b41-ace7-6507480f0cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>PostId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ContentLicense</th>\n",
       "      <th>UserDisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>this is a super theoretical AI question. An in...</td>\n",
       "      <td>2014-05-14T00:23:15.437</td>\n",
       "      <td>34.0</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>List questions are usually not suited for Stac...</td>\n",
       "      <td>2014-05-14T00:38:19.510</td>\n",
       "      <td>51.0</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>This question appears to be off-topic because ...</td>\n",
       "      <td>2014-05-14T01:16:12.623</td>\n",
       "      <td>66.0</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>This question is far too broad. It may be salv...</td>\n",
       "      <td>2014-05-14T02:00:22.797</td>\n",
       "      <td>51.0</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Nice one, @Nicholas... Another book from Hasti...</td>\n",
       "      <td>2014-05-14T02:16:20.503</td>\n",
       "      <td>24.0</td>\n",
       "      <td>CC BY-SA 3.0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  PostId  Score                                               Text  \\\n",
       "0   5       5      9  this is a super theoretical AI question. An in...   \n",
       "1   6       7      4  List questions are usually not suited for Stac...   \n",
       "2   9       7      3  This question appears to be off-topic because ...   \n",
       "3  12      15      3  This question is far too broad. It may be salv...   \n",
       "4  13      10      2  Nice one, @Nicholas... Another book from Hasti...   \n",
       "\n",
       "              CreationDate  UserId ContentLicense UserDisplayName  \n",
       "0  2014-05-14T00:23:15.437    34.0   CC BY-SA 3.0            None  \n",
       "1  2014-05-14T00:38:19.510    51.0   CC BY-SA 3.0            None  \n",
       "2  2014-05-14T01:16:12.623    66.0   CC BY-SA 3.0            None  \n",
       "3  2014-05-14T02:00:22.797    51.0   CC BY-SA 3.0            None  \n",
       "4  2014-05-14T02:16:20.503    24.0   CC BY-SA 3.0            None  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read comment data and insepct first five rows.\n",
    "comments = pd.read_xml('../data/ds/comments.xml')\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131fdaa7-27bc-41c1-b6f5-3e37b36731a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert `CreationDate` to date time.\n",
    "posts['CreationDate'] = pd.to_datetime(posts['CreationDate'])\n",
    "comments['CreationDate'] = pd.to_datetime(comments['CreationDate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74571a6-94ae-46ad-9178-dc962ddb60a4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0ff7e-ac88-4d04-ab0e-5363e1fd621a",
   "metadata": {},
   "source": [
    "We need to separate the question posts from other kinds of posts and create a column which stores our target variable: whether or not a question was answered within 7 days of posting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfa6c1d3-c8f9-41b0-90f2-5e4f99694ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate questions in a separate data frame.\n",
    "q_sel = posts.loc[:, 'PostTypeId'] == 1\n",
    "questions = posts.loc[q_sel, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a691d4f-0207-423f-ab4d-d26fd238fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate answers in a separate data frame.\n",
    "a_sel = posts.loc[:, 'PostTypeId'] == 2\n",
    "answers = posts.loc[a_sel, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15910486-157e-47a6-8bce-ebf21ef27c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dates of first answers.\n",
    "answer_dates = answers.groupby('ParentId')['CreationDate'].min().rename('AnswerDate')\n",
    "\n",
    "# Merge first answer dates with questions.\n",
    "questions = questions.merge(\n",
    "    answer_dates,\n",
    "    how='left',\n",
    "    left_on='Id',\n",
    "    right_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb567da-83c7-41f3-a20a-303087e07a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question answer time.\n",
    "answer_time = questions['AnswerDate'] - questions['CreationDate']\n",
    "\n",
    "# Target column: was the question answered within 7 days?\n",
    "questions['Answered7d'] = answer_time.dt.days <= 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397c07b-7170-4856-bb3e-59ce948f7177",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aef801-b46e-471a-9c21-6d9fef23b008",
   "metadata": {},
   "source": [
    "We wish to engineer several features for our predictive model. We first extract the hour of the day during which a question was posted, since questions posted during odd hours are more liable to be buried."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f618ffaa-7259-49d7-b6f0-8391b4edfd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hour of day from question creation time.\n",
    "questions['CreationTime'] = questions['CreationDate'].dt.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127df799-f8f9-4c77-9948-91413c41e357",
   "metadata": {},
   "source": [
    "We include the word count of question titles as a feature. Extremely short titles are unlikely to be adequately descriptive, while overly long titles may be cumbersome to read."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4698d183-fb67-41fb-83b9-ca7b3e4486fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of words in question title.\n",
    "questions['TitleWords'] = questions['Title'].str.split().apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4f3fca-7e95-465f-a0bc-d84da684d587",
   "metadata": {},
   "source": [
    "Adding tags to a question makes the question easier to search and can attract answerers interested in certain topics. We therefore include the number of tags as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04580996-b3d3-4ae2-a3fa-5ee85dfeb3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tags in questions.\n",
    "questions['NumTags'] = questions['Tags'].str.findall('<.*?>').apply(len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fe9702-3d0f-4baf-90dc-f6eb9a1d60d0",
   "metadata": {},
   "source": [
    "Overall activity on the Stack Exchange is likely to affect the probability of receiving a timely answer. If fewer questions are being asked, there is less competition and thus one's odds of receiving an answer may be higher. Likewise, if more answers are being posted, any particular question is more likely to receive an answer. We separately count the number of questions and answers on each day, take the 30-day rolling averages, and use the averages from the day prior to question posting as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9747dce-3f42-4495-996a-5a8af373c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series indexed by question creation date.\n",
    "questions_time = questions.set_index(\n",
    "    'CreationDate',\n",
    "    drop=True\n",
    ").sort_index()\n",
    "\n",
    "# Get rolling 30-day average of daily question numbers.\n",
    "daily_questions = questions_time.loc[:, 'PostTypeId'] \\\n",
    "    .resample('D').count().rename('AvgDailyQuestionCount') \\\n",
    "    .rolling(window='30D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f59a17b-6379-4dc4-a9c7-14266ce0b711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create time series indexed by answer creation date.\n",
    "answers_time = answers.set_index(\n",
    "    'CreationDate',\n",
    "    drop=True\n",
    ").sort_index()\n",
    "\n",
    "# Get rolling 30-day average of daily answer numbers.\n",
    "daily_answers = answers_time.loc[:, 'PostTypeId'] \\\n",
    "    .resample('D').count().rename('AvgDailyAnswerCount') \\\n",
    "    .rolling(window='30D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fe209bc-4ee3-4dc9-ad75-8199aeb575ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shifted 30-day average question count.\n",
    "avg_question_count= pd.Series(\n",
    "    index=questions['CreationDate'].dt.date,\n",
    "    data=daily_questions.shift(1).fillna(0)\n",
    ").reset_index(drop=True)\n",
    "avg_question_count.index = questions.index\n",
    "questions['AvgDailyQuestionCount'] = avg_question_count\n",
    "\n",
    "# Get shifted 30-day average answer count.\n",
    "avg_answer_count = pd.Series(\n",
    "    index=questions['CreationDate'].dt.date,\n",
    "    data=daily_answers.shift(1).fillna(0)\n",
    ").reset_index(drop=True).fillna(0)\n",
    "avg_answer_count.index = questions.index\n",
    "\n",
    "# Create columns for prior day's 30-day average question/answer count.\n",
    "questions['AvgDailyQuestionCount'] = avg_question_count\n",
    "questions['AvgDailyAnswerCount'] = avg_answer_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da50390-90ac-450b-8e79-decf2d04b2a9",
   "metadata": {},
   "source": [
    "It is not uncommon for people to leave comments on a question instead of an answer, especially if the question needs further clarification. Responding to such comments can often lead to an answer from the commenter. We therefore count the number of comments left by the question poster which were made before the first answer (or within 7 days of the question posting if the question was not answered within 7 days)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "449600ad-8230-4935-a73b-f24041a38dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_comments(row):\n",
    "    '''\n",
    "    Find the number of comments on a question left by the question poster\n",
    "    within 7 days (if the question is unanswered) or prior to the first answer.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    row - pandas.Series\n",
    "        A row of the a DataFrame containing Stack Exchange questions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    num_comments - int\n",
    "        The number of comments counted.\n",
    "    '''\n",
    "    # Get id of question poster.\n",
    "    id = row['OwnerUserId']\n",
    "\n",
    "    # Get cutoff date for comments.\n",
    "    date = row['AnswerDate']\n",
    "    date = row['CreationDate'] + pd.DateOffset(7) if pd.isnull(date) else date\n",
    "\n",
    "    # Count number of comments before cutoff date.\n",
    "    sel = (comments['UserId'] == id) & (comments['CreationDate'] < date)\n",
    "    num_comments = len(comments[sel])\n",
    "\n",
    "    return num_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca726f-9e2b-49ee-bd5d-327c7736bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count numner of comments.\n",
    "questions['NumComments'] = questions.apply(\n",
    "    lambda row: find_comments(row),\n",
    "    axis=1\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd987e4-c3d4-45c9-b21e-711129d76c71",
   "metadata": {},
   "source": [
    "A question asker's prior history on the Stack Exchange may be relevant to their odds of getting a question answered. Users may be uninclined to answer a question asked by someone with a reputation for asking poor or low effort questions. Likewise, users who have contribtued answers of their own may be more likely to get answers to their own questions. We engineer features to separately count the number of prior questions and answers asked by the poster, as well as the average scores of said questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e67eafd-0237-42cc-9fff-5c15677acf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prior_questions(row):\n",
    "    '''\n",
    "    Given a DataFrame row corresponding to a particular Stack Exchange question\n",
    "    , get all questions and their scores given by the question poster prior to the\n",
    "    particular question.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    row - pandas.Series\n",
    "        A row of the a DataFrame containing Stack Exchange questions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prior_questions - pandas.DataFrame\n",
    "        A DataFrame containing all prior questions from the question poster and\n",
    "        their scores.\n",
    "    '''\n",
    "    # Get id of question poster.\n",
    "    id = row['OwnerUserId']\n",
    "\n",
    "    # Find questions from the same user with date prior to the question date.\n",
    "    date = row['CreationDate']\n",
    "    sel = (questions['OwnerUserId'] == id) & (questions['CreationDate'] < date)\n",
    "    prior_questions = questions.loc[sel, 'Score']\n",
    "    \n",
    "    return prior_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90644987-ae85-4075-89a4-2fce0cade260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_prior_answers(row):\n",
    "    '''\n",
    "    Given a DataFrame row corresponding to a particular Stack Exchange question\n",
    "    , get all answers and their scores given by the question poster prior to the\n",
    "    particular question.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    row - pandas.Series\n",
    "        A row of the a DataFrame containing Stack Exchange questions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prior_answers - pandas.DataFrame\n",
    "        A DataFrame containing all prior answers from the question poster and\n",
    "        their scores.\n",
    "    '''\n",
    "    # Get id of question poster.\n",
    "    id = row['OwnerUserId']\n",
    "\n",
    "    # Find answers from the same user with date prior to the question date.\n",
    "    date = row['CreationDate']\n",
    "    sel = (answers['OwnerUserId'] == id) & (answers['CreationDate'] < date)\n",
    "    prior_answers = answers.loc[sel, 'Score']\n",
    "    \n",
    "    return prior_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c07ffc0-9275-4f5e-8259-3b53cbf7428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of prior questions.\n",
    "questions['NumPriorQuestions'] = questions.apply(\n",
    "    lambda row: len(find_prior_questions(row)),\n",
    "    axis=1\n",
    ").fillna(0)\n",
    "\n",
    "# Average score of prior questions.\n",
    "questions['AvgQuestionScore'] = questions.apply(\n",
    "    lambda row: find_prior_questions(row).mean(),\n",
    "    axis=1\n",
    ").fillna(0)\n",
    "\n",
    "# Number of prior answers.\n",
    "questions['NumPriorAnswers'] = questions.apply(\n",
    "    lambda row: len(find_prior_answers(row)),\n",
    "    axis=1\n",
    ").fillna(0)\n",
    "\n",
    "# Average score of prior answers.\n",
    "questions['AvgAnswerScore'] = questions.apply(\n",
    "    lambda row: find_prior_answers(row).mean(),\n",
    "    axis=1\n",
    ").fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79aae0d-043e-4cd2-9953-6fad51c7a381",
   "metadata": {},
   "source": [
    "We engineer a number of features which measure the types of content found in a question. These include the number of lines of code, the number of displayed math equations, and the number of lines of text in the post. We also count the number of various HTML tags that appear in questions, including `blockquote`, `ul`, and `img`.\n",
    "\n",
    "The functions used to extract these features are in the imported Python module `se_post_processing.py`, which can be found in the `src` folder of the project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cb126a9-d896-4616-bcd8-7f388262c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of lines of code.\n",
    "questions['CodeLines'] = questions['Body'] \\\n",
    "    .apply(sepp.count_code_lines)\n",
    "\n",
    "# Count number of lines of text (excluding math and code).\n",
    "questions['TextLines'] = questions['Body'] \\\n",
    "    .apply(sepp.count_text_lines)\n",
    "\n",
    "# Count number of lines of displayed math equations.\n",
    "questions['MathEquations'] = questions['Body'] \\\n",
    "    .apply(lambda x: len(sepp.find_math(x)))\n",
    "\n",
    "# Count number of quote HTML tags.\n",
    "questions[ 'Quotes'] = questions['Body'] \\\n",
    "    .apply(lambda x: sepp.count_html_tags(x, 'blockquote'))\n",
    "\n",
    "# Count number of bullet list HTML tags.\n",
    "questions['BulletLists'] = questions['Body'] \\\n",
    "    .apply(lambda x: sepp.count_html_tags(x, 'ul'))\n",
    "\n",
    "# Count number of image HTML tags.\n",
    "questions['Images'] = questions['Body'] \\\n",
    "    .apply(lambda x: sepp.count_html_tags(x, 'img'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691475af-6d7c-48f1-a111-6f411b661062",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaece3e-7842-4a89-9fd4-db2dfa28ed93",
   "metadata": {},
   "source": [
    "# 3. Modeling\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c42cfc-31cd-466c-ba82-5e791438fe25",
   "metadata": {},
   "source": [
    "With our data processing complete, we move on to modeling. The first step is to separate our data into training and test sets. We extract a random sample of $20\\%$ of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c351dd73-0ab3-4ec2-ac37-a47dffd92465",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41fbc173-af92-454a-b42a-3eef47066dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop.\n",
    "nonfeature_cols = [\n",
    "    'Answered7d',\n",
    "    'Tags',\n",
    "    'Id',\n",
    "    'PostTypeId',\n",
    "    'CreationDate',\n",
    "    'Score',\n",
    "    'ViewCount',\n",
    "    'Body',\n",
    "    'OwnerUserId',\n",
    "    'LastActivityDate',\n",
    "    'Title',\n",
    "    'AnswerCount',\n",
    "    'CommentCount',\n",
    "    'ClosedDate',\n",
    "    'ContentLicense',\n",
    "    'AcceptedAnswerId',\n",
    "    'LastEditorUserId',\n",
    "    'LastEditDate',\n",
    "    'ParentId',\n",
    "    'OwnerDisplayName',\n",
    "    'CommunityOwnedDate',\n",
    "    'LastEditorDisplayName',\n",
    "    'FavoriteCount',\n",
    "    'AnswerDate'\n",
    "]\n",
    "\n",
    "# Separate features and target variable.\n",
    "X = questions.drop(nonfeature_cols, axis=1)\n",
    "y = questions['Answered7d']\n",
    "\n",
    "# Split into training and test sets.\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef8438-1c69-47ce-b573-c896d2809089",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4ccc02-5946-4854-a211-3bf30fdcd5ab",
   "metadata": {},
   "source": [
    "We are ready to train our model. We use a random forest model to predict whether or not a question is answered within 7 days. We found that random forest performed better than logistic regression, while still being reasonably interpretable. The second point is important, as we would like to draw inferences from our model about how Stack Exchange users can structure their questions to maximize the odds of getting a timely answer. We use a cross-validated grid search to optimize the hyperparameters of our random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3bc8d1e3-1ace-44d9-b435-489c1ea94f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09875c01-538b-4c5c-8f08-ca94da987ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;model&#x27;, RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;model&#x27;: [RandomForestClassifier(max_depth=10,\n",
       "                                                           max_features=9,\n",
       "                                                           min_samples_split=6,\n",
       "                                                           n_estimators=1000)],\n",
       "                          &#x27;model__max_depth&#x27;: range(5, 55, 5),\n",
       "                          &#x27;model__max_features&#x27;: range(1, 17),\n",
       "                          &#x27;model__min_samples_split&#x27;: range(2, 12, 2)}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[(&#x27;model&#x27;, RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{&#x27;model&#x27;: [RandomForestClassifier(max_depth=10,\n",
       "                                                           max_features=9,\n",
       "                                                           min_samples_split=6,\n",
       "                                                           n_estimators=1000)],\n",
       "                          &#x27;model__max_depth&#x27;: range(5, 55, 5),\n",
       "                          &#x27;model__max_features&#x27;: range(1, 17),\n",
       "                          &#x27;model__min_samples_split&#x27;: range(2, 12, 2)}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;model&#x27;, RandomForestClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('model', RandomForestClassifier())]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'model': [RandomForestClassifier(max_depth=10,\n",
       "                                                           max_features=9,\n",
       "                                                           min_samples_split=6,\n",
       "                                                           n_estimators=1000)],\n",
       "                          'model__max_depth': range(5, 55, 5),\n",
       "                          'model__max_features': range(1, 17),\n",
       "                          'model__min_samples_split': range(2, 12, 2)}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipeline\n",
    "steps = [('model', RandomForestClassifier())]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Parameter grid\n",
    "param_grid = [{\n",
    "    'model': [RandomForestClassifier(n_estimators=1000)],\n",
    "    'model__max_depth': range(5, 55, 5),\n",
    "    'model__max_features': range(1, 17),\n",
    "    'model__min_samples_split': range(2, 12, 2)\n",
    "}]\n",
    "\n",
    "# Perform grid search.\n",
    "grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5e5d0ae7-a330-4869-aa3a-a7131b8d5574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.73      0.36      0.48     10075\n",
      "        True       0.74      0.93      0.82     19358\n",
      "\n",
      "    accuracy                           0.73     29433\n",
      "   macro avg       0.73      0.64      0.65     29433\n",
      "weighted avg       0.73      0.73      0.71     29433\n",
      "\n",
      "\n",
      "Test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.30      0.41      2549\n",
      "        True       0.71      0.90      0.79      4810\n",
      "\n",
      "    accuracy                           0.69      7359\n",
      "   macro avg       0.66      0.60      0.60      7359\n",
      "weighted avg       0.68      0.69      0.66      7359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model predictions.\n",
    "train_predict = grid.predict(X_train)\n",
    "test_predict = grid.predict(X_test)\n",
    "\n",
    "# Training classification report.\n",
    "train_cr = classification_report(y_train, train_predict)\n",
    "\n",
    "# Test classification report.\n",
    "test_cr = classification_report(y_test, test_predict)\n",
    "\n",
    "# Print classification reports.\n",
    "print('Train:')\n",
    "print(train_cr)\n",
    "print()\n",
    "print('Test:')\n",
    "print(test_cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f3bd23-b425-4c5b-bfe8-38196a05c8b6",
   "metadata": {},
   "source": [
    "The model performed reasonably well in terms of F1-score on the `1` class (question answered within 7 days). However, recall on the `0` class was poor in the test set. However, we note an improvement over our baseline model in terms of both recall on the `0` class and accuracy. In particular, the test accuracy is now higher than the majority class share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700346b6-9d00-471d-8ddd-09ef907be748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importances\n",
    "feat_imp = pd.DataFrame(\n",
    "    index=X_train.columns,\n",
    "    columns=['Importance'],\n",
    "    data=rfc.feature_importances_\n",
    ").sort_values('Importance', ascending=False)\n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac8bcd-cb4e-4c42-8ec2-e9485191187c",
   "metadata": {},
   "source": [
    "# 4. Conclusion\n",
    "---\n",
    "\n",
    "Although our baseline can reasonably predict the positive outcome (a question is answered within 7 days), it is much less effective at predicting the negative outcome. However, our model's predictions are still more accurate than those of the constant model (guessing that every question is answered within 7 days)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
